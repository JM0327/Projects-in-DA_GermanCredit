# Conclusion

```{r, echo = FALSE, message = FALSE}
source(here::here("scripts/setup.R"))
```

## **Conclusion**

For the supervised learning model, we use sensitivity, specificity,
balanced accuracy, overall accuracy and kappa to compare the quality of
different models.

For the unsupervised learning model, we perform clustering analysis to group a set of instances/features that share some common characteristics. 

### **Supervised learning**

***Table  - The scores of all models***

```{r}
final_table <- data.frame(cbind(Sensitivity=c(c1$byClass[1],
                                              c2$byClass[1],
                                              c3$byClass[1],
                                              c4$byClass[1]),
                                Specifity=c(c1$byClass[2],
                                            c2$byClass[2],
                                            c3$byClass[2],
                                            c4$byClass[2]),
                                Accuracy=c(c1$overall[1],
                                           c2$overall[1],
                                           c3$overall[1],
                                           c4$overall[1]),
                                Balanced_accuracy=c(c1$byClass[11],
                                                    c2$byClass[11],
                                                    c3$byClass[11],
                                                    c4$byClass[11]),
                                Kappa=c(c1$overall[2],
                                        c2$overall[2],
                                        c3$overall[2],
                                        c4$overall[2])))
row.names(final_table) <- c("Classification Tree(unbalanced+cv)",
                            "Classification Tree",
                            "Logistic Regression(unbalanced+cv)",
                            "Logistic Regression")

kable(final_table, caption = "The scores of four models") %>%
  kable_styling(bootstrap_options = "bordered") 
```