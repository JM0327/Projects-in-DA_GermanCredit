# 3 Data preparation for models

```{r, echo = FALSE, message = FALSE}
source(here::here("scripts/setup.R"))
```

## 3.1 Train set and test set

```{r}
set.seed(123)
index.tr <- createDataPartition(y=Credit$RESPONSE,p=0.8,list=FALSE)
Credit.tr <- Credit[index.tr,]
Credit.te <- Credit[-index.tr,]
```


```{r}
table(Credit.tr$RESPONSE)
```

# 4. supervised learning 

## 4.1 Decision tree-classification
Decision trees are algorithms that recursively search the space for the best boundary possible, until we unable them to do so (Ivo Bernardo,2021). The basic functionality of decision trees is to split the data space into rectangles, by measuring each split. The main goal is to minimize the impurity of each split from the previous one.

**Unbalanced data**
```{r}
credit.tree.unba <- rpart( RESPONSE ~ .-OBS., method= "class", 
                     data=Credit.tr, cp= 0.0001, model=TRUE)
```


```{r}
printcp(credit.tree.unba)
par(pty="s")
plotcp(credit.tree.unba)
```


```{r}
cp <- credit.tree.unba$cptable
opt <- which.min(credit.tree.unba$cptable[, "xerror"])
r <- cp[, 4][opt] + cp[, 5][opt] #1-SE role: smallest xerro+ samllest xtsd
rmin <- min(seq(1:dim(cp)[1])[cp[, 4] < r])
cp0 <- cp[rmin, 1]
cat("size chosen was", cp[rmin, 2] + 1, "\n")
```


```{r}
credit.tree.unba.prune <- prune(credit.tree.unba, cp=0.024)
rpart.plot(credit.tree.unba.prune)
```


```{r}
Credit.unba.pred <- predict(credit.tree.unba.prune,newdata=Credit.te,type="class")
draw_confusion_matrix1 <- function(cm) {
  
  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('CONFUSION MATRIX', cex.main=2)
  
  # create the matrix 
  rect(150, 430, 240, 370, col='#3F97D0')
  text(195, 440, '0', cex=1.2, font=14)
  rect(250, 430, 340, 370, col='#F7AD50')
  text(295, 440, '1', cex=1.2, font=14)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=15)
  text(245, 450, 'Actual', cex=1.3, font=15)
  rect(150, 305, 240, 365, col='#F7AD50')
  rect(250, 305, 340, 365, col='#3F97D0')
  text(140, 400, '0', cex=1.2, srt=90, font=14)
  text(140, 335, '1', cex=1.2, srt=90, font=14)
  
  # add in the cm results 
  res <- as.numeric(cm$table)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')
  
  # add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS",
       xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=15)
  text(10, 65, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=15)
  text(30, 65, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=15)
  text(50, 65, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=15)
  text(70, 65, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[7]), cex=1.2, font=15)
  text(90, 65, round(as.numeric(cm$byClass[7]), 3), cex=1.2)
  
  # add in the accuracy information 
  text(20, 35, names(cm$overall[1]), cex=1.5, font=15)
  text(20, 15, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(50, 35, names(cm$overall[2]), cex=1.5, font=15)
  text(50, 15, round(as.numeric(cm$overall[2]), 3), cex=1.4)
  text(80, 35, names(cm$byClass[11]), cex=1.5, font=15)
  text(80, 15, round(as.numeric(cm$byClass[11]), 3), cex=1.4)
}
c1 <-confusionMatrix(Credit.unba.pred, Credit.te$RESPONSE)
draw_confusion_matrix1(c1)
```


**Balanced data with Up-sampling and Cross-Validation**
```{r}
set.seed(123)
credit.tree <- caret::train(RESPONSE ~ .-OBS.,
                           data = Credit.tr,
                           method ="rpart",
                           preProcess = NULL,
                           trControl=trainControl(method="repeatedcv", number=10,
                                                  repeats=10, verboseIter=FALSE,
                                                  sampling="up"))

rpart.plot(credit.tree$finalModel)
print(credit.tree)
```

```{r}
Credit.pred <- predict(credit.tree,newdata=Credit.te)
# Measure the accuracy of the prediction
draw_confusion_matrix2 <- function(cm) {
  
  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('CONFUSION MATRIX', cex.main=2)
  
  # create the matrix 
  rect(150, 430, 240, 370, col='#3F97D0')
  text(195, 440, '0', cex=1.2, font=14)
  rect(250, 430, 340, 370, col='brown2')
  text(295, 440, '1', cex=1.2, font=14)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=15)
  text(245, 450, 'Actual', cex=1.3, font=15)
  rect(150, 305, 240, 365, col='brown2')
  rect(250, 305, 340, 365, col='#3F97D0')
  text(140, 400, '0', cex=1.2, srt=90, font=14)
  text(140, 335, '1', cex=1.2, srt=90, font=14)
  
  # add in the cm results 
  res <- as.numeric(cm$table)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')
  
  # add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS",
       xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=15)
  text(10, 65, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=15)
  text(30, 65, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=15)
  text(50, 65, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=15)
  text(70, 65, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[7]), cex=1.2, font=15)
  text(90, 65, round(as.numeric(cm$byClass[7]), 3), cex=1.2)
  
  # add in the accuracy information 
  text(20, 35, names(cm$overall[1]), cex=1.5, font=15)
  text(20, 15, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(50, 35, names(cm$overall[2]), cex=1.5, font=15)
  text(50, 15, round(as.numeric(cm$overall[2]), 3), cex=1.4)
  text(80, 35, names(cm$byClass[11]), cex=1.5, font=15)
  text(80, 15, round(as.numeric(cm$byClass[11]), 3), cex=1.4)
}
c2 <-confusionMatrix(Credit.pred, Credit.te$RESPONSE)
draw_confusion_matrix2(c2)
```


## 4.2 logistic regression

**Unbalanced data**   

```{r}
logr.bf <- glm(RESPONSE~., data=Credit.tr[2:32], family="binomial")
summary(logr.bf)
```

```{r}

logr.prob<- predict(logr.bf,newdata=Credit.te,type="response")
logr.pred <- ifelse(logr.prob >= 0.5, 1, 0) %>% as.factor()
draw_confusion_matrix3 <- function(cm) {
  
  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('CONFUSION MATRIX', cex.main=2)
  
  # create the matrix 
  rect(150, 430, 240, 370, col='#90EE90')
  text(195, 440, '0', cex=1.2, font=14)
  rect(250, 430, 340, 370, col='brown3')
  text(295, 440, '1', cex=1.2, font=14)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=15)
  text(245, 450, 'Actual', cex=1.3, font=15)
  rect(150, 305, 240, 365, col='brown3')
  rect(250, 305, 340, 365, col='#90EE90')
  text(140, 400, '0', cex=1.2, srt=90, font=14)
  text(140, 335, '1', cex=1.2, srt=90, font=14)
  
  # add in the cm results 
  res <- as.numeric(cm$table)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')
  
  # add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS",
       xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=15)
  text(10, 65, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=15)
  text(30, 65, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=15)
  text(50, 65, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=15)
  text(70, 65, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[7]), cex=1.2, font=15)
  text(90, 65, round(as.numeric(cm$byClass[7]), 3), cex=1.2)
  
  # add in the accuracy information 
  text(20, 35, names(cm$overall[1]), cex=1.5, font=15)
  text(20, 15, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(50, 35, names(cm$overall[2]), cex=1.5, font=15)
  text(50, 15, round(as.numeric(cm$overall[2]), 3), cex=1.4)
  text(80, 35, names(cm$byClass[11]), cex=1.5, font=15)
  text(80, 15, round(as.numeric(cm$byClass[11]), 3), cex=1.4)
}

c3 <-confusionMatrix(logr.pred, Credit.te$RESPONSE)
draw_confusion_matrix3(c3)

```
**Balanced data with Sub-sampling and Cross-Validation**

```{r balancing data}
set.seed(123)
n.yes <- min(table(Credit.tr$RESPONSE)) 

Credit.tr.no <- filter(Credit.tr, RESPONSE== "0") ## the "No" cases
Credit.tr.yes <- filter(Credit.tr, RESPONSE== "1") ## The "Yes" cases

index.yes <- sample(size=n.yes, x=1:nrow(Credit.tr.yes), replace=FALSE) 

Credit.tr.subs <- data.frame(rbind(Credit.tr.no, Credit.tr.yes[index.yes,])) 
table(Credit.tr.subs$RESPONSE) 
```


```{r}
set.seed(123)
logr.af <- caret::train(
  RESPONSE~.,
  data = Credit.tr.subs[,-1],
  method="glm",
  family="binomial",
  trControl=trainControl(method = "cv",
                         number = 10), 
  trace=0)
logr.af
```

```{r}
logr.pred2<- predict(logr.af,newdata=Credit.te)

draw_confusion_matrix4 <- function(cm) {
  
  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('CONFUSION MATRIX', cex.main=2)
  
  # create the matrix 
  rect(150, 430, 240, 370, col='coral1')
  text(195, 440, '0', cex=1.2, font=14)
  rect(250, 430, 340, 370, col='burlywood')
  text(295, 440, '1', cex=1.2, font=14)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=15)
  text(245, 450, 'Actual', cex=1.3, font=15)
  rect(150, 305, 240, 365, col='burlywood')
  rect(250, 305, 340, 365, col='coral1')
  text(140, 400, '0', cex=1.2, srt=90, font=14)
  text(140, 335, '1', cex=1.2, srt=90, font=14)
  
  # add in the cm results 
  res <- as.numeric(cm$table)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')
  
  # add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS",
       xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=15)
  text(10, 65, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=15)
  text(30, 65, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=15)
  text(50, 65, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=15)
  text(70, 65, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[7]), cex=1.2, font=15)
  text(90, 65, round(as.numeric(cm$byClass[7]), 3), cex=1.2)
  
  # add in the accuracy information 
  text(20, 35, names(cm$overall[1]), cex=1.5, font=15)
  text(20, 15, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(50, 35, names(cm$overall[2]), cex=1.5, font=15)
  text(50, 15, round(as.numeric(cm$overall[2]), 3), cex=1.4)
  text(80, 35, names(cm$byClass[11]), cex=1.5, font=15)
  text(80, 15, round(as.numeric(cm$byClass[11]), 3), cex=1.4)
}

c4 <-confusionMatrix(logr.pred2, Credit.te$RESPONSE)
draw_confusion_matrix4(c4)
```

## 4.3 variable importance

```{r message=FALSE, warning=FALSE, include=FALSE}
library(dplyr)
library(DALEX)

x_train <- select(Credit.tr, -RESPONSE)
y_train <- pull(Credit.tr, RESPONSE)
y_train <- as.numeric(y_train)

explainer_ct_unba <- DALEX::explain(model = credit.tree.unba.prune,
                               data = x_train,
                               y = y_train,
                               label = "Classification Tree(unbalanced data)")
explainer_ct <- DALEX::explain(model = credit.tree,
                               data = x_train,
                               y = y_train,
                               label = "Classification Tree")
explainer_glm_unba <- DALEX::explain(model = logr.bf,
                               data = x_train,
                               y = y_train,
                               label = "logistic regression(unbalanced data)")
explainer_glm <- DALEX::explain(model = logr.af,
                               data = x_train,
                               y = y_train,
                               label = "logistic regression")
```


```{r message=FALSE, warning=FALSE, include=FALSE}
set.seed(123)
calculate_importance <- function(your_model_explainer, n_permutations = 10) {
  imp <- model_parts(explainer = your_model_explainer,
                     B = n_permutations,
                     type = "ratio",
                     N = NULL)
  return(imp)
}

importance_ct_unba  <- calculate_importance(explainer_ct_unba)
importance_ct_unba[order(importance_ct_unba[,"dropout_loss"]), ]
importance_ct_unba <- importance_ct_unba %>% head(11)

importance_ct  <- calculate_importance(explainer_ct)
importance_ct[order(importance_ct[,"dropout_loss"]), ] 
importance_ct <- importance_ct %>% head(11)

importance_glm_unba  <- calculate_importance(explainer_glm_unba)
importance_glm_unba[order(importance_glm_unba[,"dropout_loss"]), ]
importance_glm_unba <- importance_glm_unba %>% head(11)

importance_glm  <- calculate_importance(explainer_glm)
importance_glm[order(importance_glm[,"dropout_loss"]), ] 
importance_glm <- importance_glm %>% head(11)
```


```{r}
library(patchwork)
p1 <- plot(importance_ct_unba) 
p2<- plot(importance_ct) 
p3 <- plot(importance_glm_unba)
p4<- plot(importance_glm)
(p1 / p3) | (p2 / p4)
```

# 5. Unsupervised learning    

## Clustering   

#### **Hierarchical clustering**

**Distance**
```{r, echo = FALSE, message = FALSE, warning=FALSE}
hierarchical.d <- dist(Credit.tr[,-32], method = "euclidean") 

hierarchical.melt <- melt(as.matrix(hierarchical.d))

kable(hierarchical.melt[1:50,], caption = "Example of the Euclidean distance between instances") %>%
  kable_styling(bootstrap_options = "bordered") %>%
  kableExtra::scroll_box(width = "100%", height = "250px")
```

**Dendrogram**   

```{r, echo = FALSE, message = FALSE, warning=FALSE, fig.height=4, fig.width=6}
hierarchical.cluster <- hclust(hierarchical.d, method = "complete")
plot(hierarchical.cluster, hang=-1)
```

**Choice of the number of clusters**

```{r, echo = FALSE, message = FALSE, warning=FALSE, fig.height=6, fig.width=8}
c.p1 <- fviz_nbclust(Credit.tr[,c(-1,-32)],
             hcut, hc_method="complete",
             hc_metric="euclidean",
             method = "wss", 
             k.max = 25, verbose = FALSE)

c.p2 <- fviz_nbclust(Credit.tr[,c(-1,-32)],
             hcut, hc_method="complete",
             hc_metric="euclidean",
             method = "silhouette", 
             k.max = 25, verbose = FALSE)

# c.p3 <-fviz_nbclust(Credit.tr,
#              hcut, hc_method="complete",
#              hc_metric="euclidean",
#              method = "gap", 
#              k.max = 25, verbose = FALSE)
c.p1 / c.p2 
```

```{r, echo = FALSE, message = FALSE, warning=FALSE, fig.height=4, fig.width=6}
plot(hierarchical.cluster, hang=-1)
rect.hclust(hierarchical.cluster, k=2)
```

```{r, echo = FALSE, message = FALSE, warning=FALSE}
clust.h <- cutree(hierarchical.cluster, k=2)
clust.comp <- data.frame(Credit.tr[,c(-1,-32)], 
                              Clust=factor(clust.h),
                              Id=row.names(Credit.tr[,c(-1,-32)]))

cluster.df <- melt(clust.comp, id=c("Id", "Clust"))
```

**Interpretation of the clusters**

```{r, fig.height=20, fig.width=20, echo = FALSE, message = FALSE, warning=FALSE}
ggplot(cluster.df, aes(y=value, group=Clust, fill=Clust)) +
  geom_boxplot() +
  facet_wrap(~variable, scale='free')+
  theme(legend.text=element_text(size=rel(4)),
        strip.text=element_text(size=17),
        axis.text =element_text(size=17))
```

#### **Partitioning methods**    

**Partitioning Around the Medoid (PAM)**   

```{r, out.width="50%", echo = FALSE, message = FALSE, warning=FALSE, fig.height=4, fig.width=6}
fviz_nbclust(Credit.tr[,c(-1,-32)],
             cluster::pam,
             method = "silhouette", 
             k.max = 25, verbose = FALSE)
```

```{r, echo = FALSE, message = FALSE, warning=FALSE, fig.height=4, fig.width=6}
pam <- cluster::pam(Credit.tr[,c(-1,-32)], k=2)
plot(cluster::silhouette(pam), border = NA, col = 1:2)

```

